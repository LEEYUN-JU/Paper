⭐논문 내용이 transformer 구조를 완전히 이해하지 않는 이상 알기 힘든 내용이다. 나중에 시간이 되면 다시 한번 읽어보자.⭐
!!! Video Prediction!!!

<Abstract>
- 기존의 많은 Human pose estimation 분야에서, 정확도와 효율성을 높이기 위해서, transformer 구조를 많이 사용했지만, 이는 temporal relation만 고려한다는 점과, dot produt self-attention caculation이 복잡하다는 단점을 가지고 있으며, 이는 embedding size에 비례한다는 단점이 있다.
- 이에, synthesized spatial and temporal attention을 믹싱하고, 우리 모델은 inter-joint와 inter-frame을 포함함으로써, 전체 비디오에서 사람의 자세를 더 잘 추정할 수 있게 해준다.

<Introduction>
- pose estimation은 지나치게 keyframe에 의존하는 경향이 있다.
- feature extracted from inputs 된것에서 좋은 것을 골라야 한다.
- ViT에서 self-attention mechanism 을 사용하여, 좋은 성능을 보여주었지만 이는 비약적으로 사이즈가 크다.
- 이를 해결하기 위해서 본 논문에서는 linear layer를 통해 attention weights을 생성하는 standard key-query attention을 사용하고자 한다.
- 우리는 우리의 모델을 MixSynthFormer라고 이름 붙였으며 contribution은 다음과 같다.
- 1) keyframe 기반의 효율적인 pose estimation 모델을 생성했다.
- 2) MLP 기반의 mixed synthetic attention matrix generation module을 사용했으며, 본 module이 하는 것은 spatially 그리고 temporally하게 attention matric을 생성하는 것이다.
- 이러한 디자인은 우리 모델이 channel-wise 그리고 token-wise 기반의 feature들을 다이나믹하게 합칠 수 있게 해주며, 자세를 효율적으로 구성한다.
- 연산량을 줄이기 위해서, attention matrix generation을 사용한다.
- 3) 우리는 2D 뿐만 아니라 3D pose estimation도 가능한 모델을 설계했다.

<Related Work>
[2.1 Human Pose Estimation]
- Human pose 모델은 두가지 타입으로 분류되는데, 하나는 frame-by-frame 이고 다른 하나는 keyframe 기반의 추정 방식이 있다.
- frame-by-frame방식으로 자세를 추정하는 경우에는 너무 많은 연산량을 요하기 때문에 비 효율적이다.
- 게다가 이러한 방식은 occlusion 되는 경우에 매우 민감하게 반응한다.

[2.2 Motion Completion and Prediction]
- motion completion 의 목표는 특정 키 프레임에서 사라진 관절을 찾아내는 것이다.
- motion prediction은 future motion을 생성해 내는 것이고, 이때 오로지 과거 프레임에 대한 정보만 주어진다.
- motion completion과 motion prediction의 유일한 차이는 키 프래임의 제한에 있다.

<Method>
[Problem Definition]
- 감지된 자세가 복잡하거나 폐색 현생이 발생한 경우에는, 추정된 자세를 신뢰할 수 없다.
- 샘플링된 프레임안에서 목표로 하는 자세를 추정하는 것을 목표로 한다(???)

[Model Overview]
- MixSynthFormer는 정확한 자세 추정을 위해서 recover하는 것이 목표이다.
- 이렇게 복원된 자세들은 linear projection에 사용되는 트랜스포머에 임베딩 되고, MixSynthEncoder의 L Block에 들어가게 된다.
- 다음으로는 MixSynth Attention에 대해서 자세하게 소개하고자 한다.

[Design of MixSynthFormer]
- 우리의 프레임 워크에서 제안하는 것은 recover-refine 방식이다.
- 우리는 MixSynthFormer를 디자인했는데, 이는 기존의 transformer방식을 따르지만 self-attention 모듈을 제외한 나머지를 사용한다.
- attention layer는 transforer encoder에서 position embedding을 위해서 필수적이지만, MLP 기반의 MixSynth Attention은 다른 토큰들에 매우 민감하기 때문에 굳이 position embedding을 위한 layer가 필요하지 않다.
- 최종적으로 얻어지는 pose sequence는 MixSynthEncoder 와 noisy pose에서 복원된 부분의 합이다.

[MixSynth Attention]
- global 그리고 local feature를 위해서, spatial 그리고 temporal synthetic attention matrices 을 섞었다. 
- 이는 relative interjoint 와 inter-frame importance를 섞은 weight이다.
- 다른 것들은 inter-frame의 관계에 영향을 많이 받는 것에 비해, inner joint의 경우 특정 동작에서 매우 중요하게 작용한다. (frame 보다 joint를 잘 추정하는것이 중요한 이유를 설명하고자 하나봄)

[SynthAttention Operation]
- embedding size의 연산량을 줄이기 위해서 우리는 SynthAttenOp를 제안하고자 한다.
- 차원 축소를 진행한다는 것.
- 입력값이 주어지면, linear > SElayer > Softmax 순서로 차원을 축소시키고, 다른 branch에서는 linear만 사용한 다음에, output으로 넘겨줄때에 앞서 가져온 결과를 concate 해 주는 것 같다.
- 여기서 핵심은 SElayer이다.

[Efficiency Calculation]
- 모델 복잡도를 줄여서 연산 속도를 향상시켰다.

[Loss Function]
- L1 loss 를 사용했다.

[Motion Prediction Setting]
- Motion prediction 과 motion completion은 conditional motion generation의 sub field 에 해당하는 연구이다.
- 우리는 short-term predcition을 sub-task로 고려하고 있다.
- historical ground-truth에 의존하여 feature를 예측하는 경향이 있다.
- future pose estimation을 위해서 우리는 L-2 norm를 사용하였다.

<Ablation Study>
- 보통 input sequence에서는 키 프레임 poses 들에서 linearly interpolated한다.
- (키가 나타나면, 이들간의 연결을 linearly interpolate한다는 의미인듯?)

[Attention Matrix Generation]
- 본 모델에서는 linear layer를 생성하는 경우에 SELayer를 사용한다.
- FPN에 의해서도 생성 가능하고, learnable matrix에서도 생성 가능하다.
- 우리의 generation model은 self-attention 모델과 비교하였다.

[Effect of Reduction Factor]
- 

[Compoenents in mixSynth Attention Block]
- 

[Conclusion]
- flexible model design이 자세 예측을 용이하게 했다.
- 포괄적인 실험을 통해 다양한 분야에도 사용 가능하다는 것을 알아냈다.

<새롭게 알게 된 용어 & 다시 정리하는 용어>
- body recovery 라는 분야가 있는지 찾아보기 
- cubic-spline : 주어진 두 점을 다항식으로 매끄럽게 연결하는 방법
- inter-joint : 주요 관절과 관절을 연결해 주는 부분

<나중에 시도해 볼만한 것들 & 논문 뒷받침 참고가 될만한 내용>
- intro가 쓸만하군. 자세 추정을 어느 분야에서 사용 가능한지, 현황에 대한 얘기.
- occlusion 상황에 대해서 언급했기 때문에 사용 가능할 듯. 2.1 HPE에서 언급함.
- occlusion recover 방식에 대해서 언급했기 때문에, 뒷받침으로 넣을 것.
- SELayer : Squeeze-and-Excitation layer

<참고한 블로그>

<논문 요약>
- attention 기반으로 feature에 가중치를 두어서 학습한다.
- SElayer를 사용하여 channel-wise한 특성을 살릴 수 있도록 한다.
- 여러가지 예측 가능한 자세를 생성하고, 생성된 자세와 정답간의 차이를 측정한다.
