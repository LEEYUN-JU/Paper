<Abstract>
- 각 frame 을 독립적으로 추정하건, across frame을 통해 pose를 tracking하던 간에, HPE는 local information에 의존한다.
- 본 논문에서는 local approach 와 global context를 결합 시키는 방법을 소개하고자 한다.
- K-FPN을 사용하고, 이는 informative frame을 선택한 다음에, 전체 sequence에서 자세를 복원하고자 한다.
- occlusion, motion blur, illumination changes, 등에 대해서도 robust하다.
- Penn Action과 sub-JHMDB에서 SOTA를 달성햇다.
- K-FPN net과 HPIM을 사용한다.

<Introduction>
- The new pipeline uses a light weighted key frame proposal network (K-FPN), 자세 추정에 모든 frame을 쓰는게 아니라 최소한의 frame만 선택하는 것
- 본 논문의 main contribution중 하나는 unsupervised training을 위한 latent space에서의 recovery error를 기반으로 하는 loss function이다.
- 남아있는 frame내에서 pose를 얻기 위해서  dynamics-based dictionary를 사용하는 Human Pose Interpolation Module(HPIM)이 second moudle의 주요한 pipeline이다.
- important한 frame을 select하는 unsupervised, 하고 light한 모델이다.
- 자세 추정시에 특정 key frame에서 추출된 정보를 활용한다.
-  key-frame이 아닌 frame으로부터 자세를 추정한다
- 수동으로 annotation되던 것들에 대한 수고를 덜 수 있다. (없던 frame 에서 추출하는 거라 원래는 사람이 정답을 만들어야 했기 때문인듯?)

<Related Work>
[Image Based Pose Estimation]
- 기존의 방법들은 body parts와 hand-crafted feature에 의존해왔다.
- [6]은 DCNNs을 parts of presence와 spatial relationships을 위한 conditional probabilities을 배우는데 사용했다.
- [40]은 end-to-end 모델과 DCNN을 결합하였다.
- [7]은 body joints의 correlation을 ImageNet pre-trained된것과 VGG-16 based모델을 통해 배웠다.
- [35] 는 articulated pose estimation을 위해서 long-range dependencies하게 model을 만들었다.
- [21] 는 서로 stacked된 feature들을 incorporate하기 위한 pathway를 opening했고, large pixel displacements를 handle하기 위한 architecture인 hourglass를 제안했다.
- sufficient scaled feature는 연산량이 많다.
- [42]는 teacher-student 구조를 제안함으로써, network complexity 를 줄이고, 연산 시간을 줄이고자 하였다.
- 마지막으로 [4, 15, 22]는 사람의 body 구조를 이용하여 keypoints의 location을 재 정의했다.

[Video Based Pose Estimation]
- [27]은 additional convolutional layer가 spatial human layout을 더 simpler하게 배울 수 있도록 한다는 것을 보여주었다.
- [20]은 image quaility degradation을 handle하기 위해서 sequenital geometric consistency를 도입했다.
- RNN 기반의 모델은 높은 연산량을 요구한다.
- [23]은 이러한 문제를 해결하기 위해서 online distill pose kernel을 제안했다.

<Proposed Approach>
- 전체 비디오 내에서 자세 추정이 가능할것 같은 몇개의 프레임만 고른다.
- annotation이 존재하지 않는 frame이기 때문에 이와 같은 task 는 challening하다.
- 제안된 architecture 에는 데이터 내에서 공간적, 시간적 상관관계가 있으며, 이는 역학을 통하여 알아낼 수 있다는 것이다.
- 따라서 key frame들은 dynamic model 과 non-selected frames들을 recover하기에 충분하다.

[Atomic Dynamics-based Representation of Temporal Data] - 너무 어려워서 대충 적기
- [19]에서 소개된 dynamics-based atomic(DYAN)을 사용한다.
- atom 이 input에서 손실된 부분을 recover하기 위해서 사용된다.
- [19]에서는 dictionary D는 future frame을 예측하기 위해서 학습하고, loss를 최소화 하고, input, loss fucntion을 최소화 한다.
- 본 논문에서는, 더 좋은 key frame selecetion를 예측하고, 이를 기반으로 학습하는 다른 loss function을 제안한다.

[Architecture, Training, and Inference]
- 

[Online Key Frame Detection]
- 선택된 key frame이 좋은 것인지 판별하기 위한 discriminator를 설치하여 구분한다.
- discriminator는 새로운 input frame과 지금까지 선별된 frame 중에서 예측된 특징을 구별하도록 훈련된다.
- 현재 키 프레임의 atom dynamics-based 기반 표현과 관련 역학 기반 사전 확장을 곱하여 생성된다.
- new frame이 특징을 정확하게 예측하지 못하더라도, 새로운 정보이기 때문에, 이는 항상 핵심 frame에 포함되어야 한다는 것이다.

[Experiments]
- 데이터 셋으로는 PennAction과 sub-JHMDB를 사용했다.
- video가 40 frame이 넘어가는 경우에는 임의로 40개를 골랐다.

<새롭게 알게 된 용어 & 다시 정리하는 용어>
- 

<나중에 시도해 볼만한 것들 & 논문 뒷받침 참고가 될만한 내용>
- 

<참고한 블로그>

<논문 요약>
