<Abstract>
- 본 논문에서 집중적으로 보고자 하는 것은 multi-person end-to-end 자세 추정시에 발생하는 문제에 대해 연구하고자 한다.
- 현재 달성된 sota모델에서는 DETR-like 프레임 워크를 채택했으며, 복잡한 decoder구조를 가지고 있다는 특징이 있다.
- 우리는 단순한 transformer 기반의 방법을 제시하고자 한다.
- self-attention 모듈을 두개의 subsequent group으로 나누었다.
- 1) N within-instance self-attention 쿼리와, K 개의 keypoints 쿼리
- 2) (K+1)개의 same-type across-instance self-attention, 같은 유형의 N개의 쿼리
- 디코더는 최종적으로 across-instance type-different 쿼리를 통해 interaction에 해당하는 부분을 제거한 결과를 내놓고, 이를 통해 성능을 향상 시킬 수 있었다.

<Introduction>
- multi-person에 대한 자세 추정 모델을 end-to-end 프레임 워크로 설계했다.
- DETR 프레임 워크에서는, 트랜스포머의 인코더-디코더 구조를 따라했다.
- PETR은 체계적으로 키 포인트의 위치를 예측하고자 했고, 두개의 subsequent 디코더, pose 디코더, 그리고 joint 디코더를 사용했다.
- ED-Pose에서는 box 감지 문제로 보고, content 쿼리와 box 쿼리를 보도록 했다.
- single 쿼리를 사용하는 대신에, N X K 키포인트 쿼리를 사용하기로 했다. 
- N은 instance 쿼리를 뜻하고, K는 키포인트 자세 추정 예측에 사용되는 score를 뜻한다.
- 기본적으로 사용되는 self-attention 을 두개의 subsequent self-attention group으로 대체하였다.
- 첫 번째 그룹의 "self-attention"은 "N" 개의 병렬 self-attentions로 구성되며, 각 self-attention은 "K" 개의 keypoint queries와 해당 인스턴스 쿼리를 가지고 있습니다. 이것은 운동학적 관계를 활용하고 예측된 포즈에 대한 정보를 수집하기 위한 것입니다. 여기서 "N"은 인스턴스의 수, "K"는 각 인스턴스의 키포인트 쿼리 수를 나타냅니다.
- 두 번째 그룹의 "self-attention"은 이전과 같이 "K + 1" 병렬 self-attentions로 구성되며, 각 self-attention은 "N" 개의 동일한 유형의 쿼리를 가지고 있습니다. 이는 예측 정보의 중복을 수집하기 위한 것으로 원래 DETR에서 사용되던 self-attention과 유사합니다.
- 두 개의 self-attention 은 두 종류의 상호작용을 찾아내기 위함이다.
- (1) K개의 키포인트 쿼리 와 one instance 쿼리의 상관관계를 within N 개 내로 찾아내는 것
- (2) 같은 유형의 n개의 쿼리에 대한 (K+1)개의 across-instance 상호작용. (nose keypoint 쿼리 혹은 instance query)
- (3) standard self-attention 내에서, 다른 타입들의 쿼리에 대한 추가 상호작용은 직접적으로 영향력은 없지만, optimization을 쉽게 만들어주기 때문에 성능 향상에 도움이 된다.
- 즉, 본 논문에서는 두 개의 interaction을 두 개의 subseqent group self-attention을 사용해 분리하고자 한다.
- 특히 같은 종류이며, 쿼리가 같은 사람에게 국한되었을때 정보를 찾는 경우에 한해서.

<Related Work>
- multi-person pose estimation 은 크게 end-to-end 방식과 아닌 방식으로 나누어 볼 수 있다.

[Non-end-to-end methods]
- top-down 방식의 경우 2-stage 방식이고, bottom-up 방식의 경우 one-stage방식으로 구성되어 있으며, 나머지 내용은 기존에 알던 지식과 별반 다르지 않은 내용이다.

[End-to-end methods]
- PETR과 DETR을 거론하며 간략하게 설명함.
- PETR의 경우, 최초로 joint decoder라는 것을 도입하여 사용함.
- QueryPose (Sparse R-CNN을 사용하고, RoIAlign 기반의 디코더를 사용함)
- ED-Pose (pose estimation 을 최초로 키 포인트 box detection에 대한 문제라고 언급함.
  총 두개의 쿼리를 사용하는데, human-to-keypoint 쿼리와 각 key points 들에 대한 box  쿼리를 사용함)

- 앞서 설명한 방법들은 너무 복잡하다. 따라서 본 논문에서는 간소화된 decoder를 사용한 방법을 제안하고자 한다.

<Group Pose>
- 복잡한 디코더 대신에 심플한 디코더를 사용하여 문제를 해결하였고, multi-person pose를 예측하는 모델을 생성하고자 하였다,

<Over view>
- group pose는 head의 위치를 예측하는 것을 중점으로 하고 있다.
- 이는 head를 찾게 되면, 나머지 17개에 해당하는 키 포인트를 찾는것이 용이하기 때문이다.
[Backbone and transfoermer encoder]
- 우리는 DETR 프레임 워크를 backbone으로 사용했다.
- 입력은 이미지로 받고 결과물은 multi-level feature로 반환한다.
[Transofermer decoder]
- 디코더 부분에서는 N X K개의 키포인트 쿼리를 사용하고, single 쿼리를 사용하여 자세를 추정하는 것이 아니라 N개의 instance 쿼리를 사용하여 자세를 예측한다.
- 키포인트 쿼리는 각 키포인트를 객체로 간주하고 N × K 키포인트 위치를 재설정하는 데 사용되며, 각 인스턴스 쿼리는 해당 K 키포인트 포즈 예측을 점수화하는 데 사용한다.
- 트랜스포머 디코더를 simple하게 사용하고자 하였다.
- 특히, self-attention을 두개의 subsequent 그룹 self-attention으로 대체하고, decoder layer가 같은 사람에 한해서 쿼리들간의 상호작용을 가능하게 하도록 한다.
[Prediction heads]
- 그룹 포즈는 N 개의 사람 자세를 예측하고, 각 자세는 classification 점수와, K keypoint position를 포함한다.
[Loss function]
- 헝가리안 매칭 알고리즘은 예측된 자세와 정답 포즈간의 one-to-one assignmet를 사용한다.
- loss function은 classification loss와 regression loss로 구성되어 있다.
- keypoint regression loss는 l_1 loss와 OKS loss의 조합으로 되어 있다.

<N X K keypoint queries and N instance queries>
- multi-person pose estimation에서, 프레임 워크는 N개의 사람의 자세와 K개의 키포인트를 주어진 이미지내에서 찾는 것이다.
- 그룹 포즈는 human instance를 K개의 키포인트 쿼리와 한개의 인스턴스 쿼리의 조합으로 볼 수 있다.
- 두 쿼리는 각각 다른 일을 하기 때문에, 초기화와 구성을 별도로 하였다.
[Query construction]
- 트랜스포머 인코더로부터 나온 결과물을 사람의 instance를 정하고, 예측하는데 사용한다.
- N개의 human instance를 기반으로 classification score를 계산한다음에, 선택된 N개의 자세에 대한 memory feature를 도출한다.
- 이것을 기반으로 keypoint 쿼리를 구성하고 초기화 한다. 
- N × K 키포인트 쿼리의 경우 무작위로 초기화된 K 키포인트 임베딩(K × D)과 해당 출력 메모리 기능(1 × D)을 결합하여 각 인간 인스턴스에서 K 키포인트 쿼리(K × D)의 내용 부분을 구성합니다.
- 그리고 각 인간 인스턴스에서 K개의 키포인트 쿼리(K × 2)의 위치 부분은 해당 예측된 K개의 키포인트 포즈(K × 2)로 초기화됩니다.
- N개 인스턴스 쿼리의 경우 컨텐츠 부분만 고려하고 각 인간 인스턴스에 대해 무작위로 초기화된 학습 가능한 인스턴스 임베딩(1 × D)을 사용합니다.
- 이는 인스턴스 쿼리의 경우, classification task만 시행하고, 구체적인 position inforamtion을 요구하지 않기 때문이다.
- cross-attnetion을 디코더 레이어에서 수행하는 경우, 개개인에 대한 인스턴스 쿼리의 reference point는 K keypoint position의 평균을 사용한다.

<Group self-attentions>
- DETR모델에서는 self-attention을 쿼리간의 상호 작용, 다른 쿼리로부터의 정보 수집 그리고 instance 중복 제거에 사용한다.
- 이는 group Pose와 사뭇 다른데, group pose에는 두 가지 타입의 쿼리가 존재한다.
- 하나는 K keypoint 쿼리이고, 다른 하나는 human instance에 대한 쿼리이다.
- 각기 다른 across-instance 쿼리에 대한 상호 작용 (instance 쿼리와 keypoint 쿼리에 대한 것)은 직접적으로 성능을 올리는데 크게 도음이 되지 않는다.
- 따라서 gruoup self-attention을 사용했다.
[N within-instance self-attentions]
- 쿼리들 간의 상호 작용을 설계하고, kinematic 한 관계를 이용하고, pose 예측 점수에서 정보를 얻었다.
- N개의 human instance 를 (K+1) X (K+1) 형태로 병렬로 N self-attention map을 계산한다.
- 단, 배치 사이즈나 head의 사이즈는 생략한다.
[K+1 same-type across-instance self-attentions]
- 앞서 설명한 group-self-attention 뿐만 아니라, 다른 instance 내에서의 같은 타입의 쿼리에서 정보를 수집하고, 똑같은 예측값을 제거하도록 하였다.
- 같은 유형의 쿼리, 각 키포인트의 쿼리, K+1 의 같은 타입의 across instance selft-attnetion의 결과에 대해서는 human instance에 대해서 서로 상호 작용 가능하도록 설계하였다.
- 이는 한개의 self-attnetion module에서 병렬 처리를 가능하도록 하였으며, K+1개의 self attention-map을 N X N형태로 계산 가능하도록 하였다.
- 기존의 self-attention과 비교해 보았을때, 우리는 두개의 subsequent group self-attnetion을 통하여 쿼리에 대한 같은 사람의 그리고 같은 유형의 instance 정보를 수집하도록 하였다.
- 이는 다른 타입의 쿼리에서 across-instacne 상호작용을 제거함으로써 가능하게 되었다.
- 섹션 4.3 에서는 상호작용 제거가 실질적인 결과에 어떻게 영향을 미치는지 보여준다.

<4 Experiments>
- COCO데이터 셋을 사용하고, Crowd-pose 도 사용했다.

[Ablation Study]
- query designs for human instance : instance query 와 keypoints는 group pose내에서 필수적이며, key points 쿼리는 multi-person 의 자세를 추정하는데 중요하고, 이를 제거한 경우, 약 6.0 AP하락을 보여주었다. instance query 는 두가지 측면에서 좋다는 것을 확인했는데, 하나는 human instance 내에서 정보를 수집하는 부분과, classification task와 key points regression task기능을 분리시키는 역할을 한다.

- self-attnetion implementations : decoder layer, N X (K+1) 쿼리, attention mask, group self-attnetion 에 대한것을 비교했다. across-instance 를 위한 서로 다른 타입의 쿼리는 pose estimation task에 크게 도움이 되지 않았다. 이러한 상호작용을 없애는 것이 모델을 더 빠르고, 성능을 높여준다는 것을 알아냈다. instance 별로 parameter를 다르게 하여 학습시키는 것이 더 좋다는 결과를 얻었다.

- group self-attentions : K keypoint queries 그리고 one instance query (K+1) across-instance self-attnetion 그룹에 대한 self-atttnetion 을 제거한 결과 -5.0AP 가 떨어지는 것을 관측했다. 이 두가지 interactio은 multi-person pose estimation 에 있어서 매우 중요한 역할을 한다는 것을 알아내게 되었다. 두 가지 instance self-attnetion은 kinematic 관계에 대한 정보를 얻어내는 것과, pose prediction에 대한 점수를 매기는 것에 영향을 미친다. 왜냐하면, 이러한 것들은 같은 유형의 keypoints queries 나 instance queries로부터 같은 유형의 정보를 얻어내는 것이 가능하여, 중복된 정보를 제거할 수 있기 때문이다. 

- number of instances : 사전에 정의되어 있는 human instance 가 결과에 어떤 영향을 미치는지 알아보고자 하는 실험이다. 실험을 통해 총 100개의 human instance 를 가지게 되는 경우, 성능을 도출하기에 충분하다는 것을 알아냈다.

<4.4 More Analysis>
- Analysis on model converge : ED Pose 에서는 multi-person pose estimation task를 두개의 sub-processes로 나누어서 생각하였고, 하나는 human instance 를 detect 하는 과정, 다른 하나는 keypoints를 detection 하여 자세를 추정하는 것으로 나누었다. decoder단에서는 human instances 초기화(converge 를 더 빠르게 해줌) 에 좋은 효과를 보여주었다. 이러한 점에 착안하여 ED-Pose와 유사한 구조로 설계하도록 했다.

- Analysis on model inference speed : end-to-end 프레임 워크에서, inference time과 FPS 를 비교했다. 단순한 디자인일 수록 좋은 성능을 보여주었다. simple transformer를 사용하는 것이 오히려, 복잡한 구조보다 좋은 성능을 보여준다는 것을 확인했다. 

<5. Conclusion>
- 본 논문에서, Group pose 라는 multi-person pose estimation에 대한 simple baseline을 제시하였다. 
- 쿼리와 decoder self-attention을 단순한 구조로 디자인 하여 속도를 개선하였다.

<새롭게 알게 된 용어 & 다시 정리하는 용어>
- DETR (Detection with Transformer) : 네트워크 구조가 단순하면서 end-to-end가 가능한 DETR을 facebook 에서 공개함. 
  CNN Backbone + Transformer + FFN (Feed Forward Network)로 구성되어 있음.
  feautre는 CNN을 통해서 뽑아내고, 이를 transformer의 입력값이 될 수 있도록 가공해줌 > transformer의 결과값을 FFN을 통과  시킴
- PETR (Position Embedding Transformation) : 

<나중에 시도해 볼만한 것들 & 논문 뒷받침 참고가 될만한 내용>
- top-down 방식과 bottom-up 방식을 end-to-end 인지 아니면 non 인지에 따라서 구별하여 서술한 점이 흥미로웠음.

<참고한 블로그>
- https://wikidocs.net/145910 > DETR
- https://github.com/megvii-research/PETR

<논문 요약>
- 구조를 단순하게 하여 속도를 개선시켰다.
- 복잡한 구조를 단순하게 변경하였으며, queries를 최대한 세세하게 분리하여 성능을 높였다.
- instance queires 와 keypoint queries 로 나누었고, 이는 성능 향상을 도모하였으며, 각각 파라미터를 다르게 설정하여 성능이 좋아지는 것을 확인 할 수 있었다.
