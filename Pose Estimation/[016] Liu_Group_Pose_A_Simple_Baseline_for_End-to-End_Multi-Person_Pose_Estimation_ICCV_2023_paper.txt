<Abstract>
- 본 논문에서 집중적으로 보고자 하는 것은 multi-person end-to-end 자세 추정시에 발생하는 문제에 대해 연구하고자 한다.
- 현재 달성된 sota모델에서는 DETR-like 프레임 워크를 채택했으며, 복잡한 decoder구조를 가지고 있다는 특징이 있다.
- 우리는 단순한 transformer 기반의 방법을 제시하고자 한다.
- self-attention 모듈을 두개의 subsequent group으로 나누었다.
- 1) N within-instance self-attention 쿼리와, K 개의 keypoints 쿼리
- 2) (K+1)개의 same-type across-instance self-attention, 같은 유형의 N개의 쿼리
- 디코더는 최종적으로 across-instance type-different 쿼리를 통해 interaction에 해당하는 부분을 제거한 결과를 내놓고, 이를 통해 성능을 향상 시킬 수 있었다.

<Introduction>
- multi-person에 대한 자세 추정 모델을 end-to-end 프레임 워크로 설계했다.
- DETR 프레임 워크에서는, 트랜스포머의 인코더-디코더 구조를 따라했다.
- PETR은 체계적으로 키 포인트의 위치를 예측하고자 했고, 두개의 subsequent 디코더, pose 디코더, 그리고 joint 디코더를 사용했다.
- ED-Pose에서는 box 감지 문제로 보고, content 쿼리와 box 쿼리를 보도록 했다.
- single 쿼리를 사용하는 대신에, N X K 키포인트 쿼리를 사용하기로 했다. 
- N은 instance 쿼리를 뜻하고, K는 키포인트 자세 추정 예측에 사용되는 score를 뜻한다.
- 기본적으로 사용되는 self-attention 을 두개의 subsequent self-attention group으로 대체하였다.
- 첫 번째 그룹의 "self-attention"은 "N" 개의 병렬 self-attentions로 구성되며, 각 self-attention은 "K" 개의 keypoint queries와 해당 인스턴스 쿼리를 가지고 있습니다. 이것은 운동학적 관계를 활용하고 예측된 포즈에 대한 정보를 수집하기 위한 것입니다. 여기서 "N"은 인스턴스의 수, "K"는 각 인스턴스의 키포인트 쿼리 수를 나타냅니다.
- 두 번째 그룹의 "self-attention"은 이전과 같이 "K + 1" 병렬 self-attentions로 구성되며, 각 self-attention은 "N" 개의 동일한 유형의 쿼리를 가지고 있습니다. 이는 예측 정보의 중복을 수집하기 위한 것으로 원래 DETR에서 사용되던 self-attention과 유사합니다.
- 두 개의 self-attention 은 두 종류의 상호작용을 찾아내기 위함이다.
- (1) K개의 키포인트 쿼리 와 one instance 쿼리의 상관관계를 within N 만큼 찾아내는 것
- (2) (K+1) across-instance 상호작용인데 이는 같은 타입이며 N개의 쿼리에 걸쳐있다. (?)
- (3) 다른 type 들에 대해 across-instance 를 상호 적용하고자 한다
- 즉, 본 논문에서는 두 개의 interaction을 두 개의 subseqent group self-attention을 사용해 분리하고자 한다.
- 특히 같은 종류이며, 쿼리가 같은 사람에게 국한되었을때 정보를 찾는 경우에 한해서.

<Related Work>
- multi-person pose estimation 은 크게 end-to-end 방식과 아닌 방식으로 나누어 볼 수 있다.

[Non-end-to-end methods]
- 

<논문 본론>

  
<지적된 기존 문제>

<제시하는 해결 방법>

<새롭게 알게 된 용어 & 다시 정리하는 용어>

- 

<나중에 시도해 볼만한 것들 & 논문 뒷받침 참고가 될만한 내용>

<참고한 블로그>

<논문 요약>

